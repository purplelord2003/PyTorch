{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOf1Ntc0Yh22f43zntgSVm7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1b0fcc764bc54f75962eadaddd3dfc3b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f19275cf819f448da63fdc1ac1f88d50","IPY_MODEL_f81278bd256d4d879c99603ad3d8a113","IPY_MODEL_f9379902f80e452e802cb34060af53c7"],"layout":"IPY_MODEL_6e061beb21cb4438b13812289de86bb8"}},"f19275cf819f448da63fdc1ac1f88d50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8882758b0be84dd1b7b3f204635c6033","placeholder":"​","style":"IPY_MODEL_bdaeec842cab4cb29df985b738685d87","value":" 20%"}},"f81278bd256d4d879c99603ad3d8a113":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_81125dca20e340e4b05e9e25846ce63b","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c0969ab38154245a9f5d4ec03533e00","value":1}},"f9379902f80e452e802cb34060af53c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d15585a792804f66829ce0d788d95223","placeholder":"​","style":"IPY_MODEL_70548b62ea934f239223d2c8e69f6d7c","value":" 1/5 [00:04&lt;00:17,  4.31s/it]"}},"6e061beb21cb4438b13812289de86bb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8882758b0be84dd1b7b3f204635c6033":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdaeec842cab4cb29df985b738685d87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81125dca20e340e4b05e9e25846ce63b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c0969ab38154245a9f5d4ec03533e00":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d15585a792804f66829ce0d788d95223":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70548b62ea934f239223d2c8e69f6d7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## PyTorch Transfer Learning\n","\n","* Taking parameters of what one model has learnt on another dataset and applying them to our own problem\n","\n","* Pretrained models = foundation moddels\n","\n","\n"],"metadata":{"id":"zEoqaJUm8pg6"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"qC37-A-543ej","executionInfo":{"status":"ok","timestamp":1706086665778,"user_tz":-480,"elapsed":5270,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}}},"outputs":[],"source":["import torch\n","import torchvision"]},{"cell_type":"code","source":["torchvision.__version__ # need 0.13+"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Cm6zDhEQ8feK","executionInfo":{"status":"ok","timestamp":1706086665778,"user_tz":-480,"elapsed":13,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}},"outputId":"e4e186c4-36ee-44fa-c315-ed2044d35764"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'0.16.0+cu121'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["torch.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"xtYwf6E49J86","executionInfo":{"status":"ok","timestamp":1706086665778,"user_tz":-480,"elapsed":4,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}},"outputId":"b08719e6-ef02-4089-d854-35c3942b49b2"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.1.0+cu121'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["Import the code we have written in previous sections (especially the scripts) from GitHub + torchinfo"],"metadata":{"id":"FDUX3Bq09ijU"}},{"cell_type":"code","source":["# Continue with regular imports\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision\n","\n","from torch import nn\n","from torchvision import transforms\n","\n","# Try to get torchinfo, install it if it doesn't work\n","try:\n","    from torchinfo import summary\n","except:\n","    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n","    !pip install -q torchinfo\n","    from torchinfo import summary\n","\n","# Try to import the going_modular directory, download it from GitHub if it doesn't work\n","try:\n","    from going_modular.going_modular import data_setup, engine\n","except:\n","    # Get the going_modular scripts\n","    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n","    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n","    !mv pytorch-deep-learning/going_modular .\n","    !rm -rf pytorch-deep-learning\n","    from going_modular.going_modular import data_setup, engine"],"metadata":{"id":"BDjV4BFH-ODG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706086706666,"user_tz":-480,"elapsed":40892,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}},"outputId":"e9697ae6-9000-4cca-a28a-be047c2aac01"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Couldn't find torchinfo... installing it.\n","[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\n","Cloning into 'pytorch-deep-learning'...\n","remote: Enumerating objects: 4056, done.\u001b[K\n","remote: Counting objects: 100% (1244/1244), done.\u001b[K\n","remote: Compressing objects: 100% (239/239), done.\u001b[K\n","remote: Total 4056 (delta 1079), reused 1090 (delta 1002), pack-reused 2812\u001b[K\n","Receiving objects: 100% (4056/4056), 651.13 MiB | 34.02 MiB/s, done.\n","Resolving deltas: 100% (2372/2372), done.\n","Updating files: 100% (248/248), done.\n"]}]},{"cell_type":"code","source":["# device agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"gyDrqkBq_A7N","executionInfo":{"status":"ok","timestamp":1706086707240,"user_tz":-480,"elapsed":12,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}},"outputId":"621d5f33-16c8-4d9f-e613-3c5f016ac4c8"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["# Get data of pizza, steak, sushi"],"metadata":{"id":"bZR6ukaIAJyT"}},{"cell_type":"code","source":["import os\n","import zipfile\n","\n","from pathlib import Path\n","\n","import requests\n","\n","# Set up data path\n","data_path = Path(\"data/\")\n","image_path = data_path / \"pizza_steak_sushi\" # images from a subset of classes from Food101 Dataset\n","\n","# If image folder does not exist, download\n","if image_path.is_dir():\n","  print(f\"{image_path} directory exists, skipping redownload...\")\n","else:\n","  print(f\"Did not find {image_path}, downloading it...\")\n","  image_path.mkdir(parents=True, exist_ok=True)\n","\n","  # Download data\n","  with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n","    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n","    print(\"Downloading pizza, steak, sushi data...\")\n","    f.write(request.content)\n","\n","  # Unzip data\n","  with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n","    print(\"Unzipping pizza, steak, sushi data...\")\n","    zip_ref.extractall(image_path)\n","\n","  # Remove .zip file\n","  os.remove(data_path / \"pizza_steak_sushi.zip\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kB9NAT4XAPJH","executionInfo":{"status":"ok","timestamp":1706086707895,"user_tz":-480,"elapsed":664,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}},"outputId":"1cdc3fe6-68be-4aa0-fa33-28a0f86d1e55"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Did not find data/pizza_steak_sushi, downloading it...\n","Downloading pizza, steak, sushi data...\n","Unzipping pizza, steak, sushi data...\n"]}]},{"cell_type":"code","source":["# Set up directory path\n","train_dir = image_path / \"train\"\n","test_dir = image_path / \"test\"\n","\n","train_dir, test_dir"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"taE-UL_fB_7e","executionInfo":{"status":"ok","timestamp":1706086707895,"user_tz":-480,"elapsed":3,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}},"outputId":"e3fc58ff-819c-4baa-bb6e-7551e0ad3512"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(PosixPath('data/pizza_steak_sushi/train'),\n"," PosixPath('data/pizza_steak_sushi/test'))"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["## Create Datasets and DataLoaders\n","\n","Now we've got some data, want to turn it into PyTorch DataLoaders.\n","\n","We can use `data_setup.py` and `create_dataloaders()` we made in going_modular section.\n","\n","We have to think about how to **transform** the data.\n","\n","With `torchvision` 0.13+ we can:\n","1. Manually created transforms - you define what transforms you want your data to go through\n","\n","2. Automatically created transforms - transform for your data is defined by the model you would like to use\n","\n","When using a pretrained model, its important that the data (including your custom data) that you pass through it is **transformed** in the same way the data the model was trained on else performance degredation"],"metadata":{"id":"UrUR-v9DCHGM"}},{"cell_type":"markdown","source":["## Creating a transform for `torchvision.models` manually\n","\n","`torchvision.models` contain the pretrained models"],"metadata":{"id":"C_SrSSuEDrMr"}},{"cell_type":"code","source":["from torchvision import transforms\n","# From the documentation (older release) of torchvision.models\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                 std=[0.229, 0.224, 0.225])\n","\n","manual_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)), # resize image to 224 x 224\n","    transforms.ToTensor(),\n","    normalize # images have the same distribution as ImageNet where the pretrained model has trained\n","])\n"],"metadata":{"id":"1pcG3IYrDz29","executionInfo":{"status":"ok","timestamp":1706086707895,"user_tz":-480,"elapsed":2,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from going_modular.going_modular import data_setup\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n","                                                                               test_dir=test_dir,\n","                                                                               transform=manual_transforms,\n","                                                                               batch_size=32)\n","\n","train_dataloader, test_dataloader, class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uoD8zcUXGZgG","executionInfo":{"status":"ok","timestamp":1706086707895,"user_tz":-480,"elapsed":2,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}},"outputId":"b3beeace-f0c3-4a9a-a891-c2e7b9d1ac7d"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<torch.utils.data.dataloader.DataLoader at 0x7eab17cdce20>,\n"," <torch.utils.data.dataloader.DataLoader at 0x7eab17cdcb80>,\n"," ['pizza', 'steak', 'sushi'])"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## Auto creation of transform for `torchvision.models`\n","\n","As of the current version of torchvision, there is now support for automatic data transform creation based on the pretrained model we are using"],"metadata":{"id":"NsUItRdsGyvO"}},{"cell_type":"code","source":["# Get a set of pretrained model weights\n","weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # DEFAULT refers to the best performing weight here default refers ImageNet1k (model was trained on it)\n","weights"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7r9FLIC8HD5n","executionInfo":{"status":"ok","timestamp":1706086708313,"user_tz":-480,"elapsed":420,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}},"outputId":"5c450a18-fbb4-4a56-c04c-282fc3b93e3a"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EfficientNet_B0_Weights.IMAGENET1K_V1"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Get the transforms used to create our pretrained weights\n","\n","auto_transforms = weights.transforms()\n","auto_transforms"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gUPA8OYdIwp0","executionInfo":{"status":"ok","timestamp":1706086708313,"user_tz":-480,"elapsed":5,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}},"outputId":"b6ea42dd-77e2-4953-efaf-fa6842b4a72f"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ImageClassification(\n","    crop_size=[224]\n","    resize_size=[256]\n","    mean=[0.485, 0.456, 0.406]\n","    std=[0.229, 0.224, 0.225]\n","    interpolation=InterpolationMode.BICUBIC\n",")"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Create dataloaders using automatic transforms\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n","                                                                               test_dir=test_dir,\n","                                                                               transform=auto_transforms,\n","                                                                               batch_size=32)\n","\n","train_dataloader, test_dataloader, class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QIy613lzJGw2","executionInfo":{"status":"ok","timestamp":1706086708313,"user_tz":-480,"elapsed":4,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}},"outputId":"8c3b949c-f8f1-45cf-a9d5-821423a1a596"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<torch.utils.data.dataloader.DataLoader at 0x7eab17cdfbe0>,\n"," <torch.utils.data.dataloader.DataLoader at 0x7eab17cddd50>,\n"," ['pizza', 'steak', 'sushi'])"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["## Where to get pretrained models\n","1. PyTorch domain libraries\n","2. Libraries like `timm`\n","3. HuggingFace Hub\n","4. Paperswithcode"],"metadata":{"id":"1OocNAPdJ_5g"}},{"cell_type":"markdown","source":["## Which pretrained model should you use?\n","\n","Need to experiment with various models\n","\n","* Take a well-performing model from a problem space similar to\n","your own\n","\n","Three things to consider:\n","1. Speed - how fast does it run\n","2. Size - how big is the model\n","3. Performance - how well does it go on your chosen problem\n","\n","Where does the model live?\n","\n","Is it on device? (like a self-driving car)\n","\n","Or does it live on a server?\n","\n","E.g. for FoodVisionMini we need small size to deploy mobile phone (using computing power of a phone as well) but yet good performance (EffNetB0 has high accuracy with low parameters) --> performance vs size\n","\n","If we had infinite compute, we will choose biggest model + params + accuracy etc"],"metadata":{"id":"7-k2mtFKKICs"}},{"cell_type":"markdown","source":["## Setting up a pretrained model\n","\n","Want to create an instance of EffNetB0"],"metadata":{"id":"F4YgaBJvKj3G"}},{"cell_type":"code","source":["# Creating a pretrained model (torchvision v0.13+)\n","\n","# Bug in current torchvision version in google colab\n","# fix\n","from torchvision.models._api import WeightsEnum\n","from torch.hub import load_state_dict_from_url\n","\n","def get_state_dict(self, *args, **kwargs):\n","    kwargs.pop(\"check_hash\")\n","    return load_state_dict_from_url(self.url, *args, **kwargs)\n","WeightsEnum.get_state_dict = get_state_dict\n","# endfix\n","\n","# Creating a pretrained model\n","weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights\n","model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n","\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FewX23mZNE7-","executionInfo":{"status":"ok","timestamp":1706086708990,"user_tz":-480,"elapsed":681,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}},"outputId":"e2124ab1-87fb-4eec-d283-68187e311834"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-3dd342df.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-3dd342df.pth\n","100%|██████████| 20.5M/20.5M [00:00<00:00, 69.9MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["EfficientNet(\n","  (features): Sequential(\n","    (0): Conv2dNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): SiLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (2): Conv2dNormActivation(\n","            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n","      )\n","    )\n","    (2): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n","      )\n","    )\n","    (3): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n","      )\n","    )\n","    (4): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n","      )\n","    )\n","    (6): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n","      )\n","      (3): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n","      )\n","    )\n","    (7): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n","      )\n","    )\n","    (8): Conv2dNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): SiLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=1)\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=True)\n","    (1): Linear(in_features=1280, out_features=1000, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["model.classifier # 1000 outfeatures as it was trained on the ImageNet (1000 classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LJLI86M3Q3dU","executionInfo":{"status":"ok","timestamp":1706086708990,"user_tz":-480,"elapsed":7,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}},"outputId":"924f0827-49c4-4566-f562-34aed5dc29fd"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Dropout(p=0.2, inplace=True)\n","  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",")"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["Model has:\n","1. Features (extract features from images)\n","2. Avgpool (turns features into feature vector by taking the average)\n","3. Classifier (turns feature vector into prediction logits and the out_features can be adjusted to the number of classes you have)\n","\n","Feature extraction is this (simply adjusting the last line from the model backbone) with the feature extraction layers frozen, only the input dataset and the output shape changes.\n","\n","You can do fine-tuning of the feature extraction model if you have lots of data where you start to adjust the individual feature extraction layers\n","\n","Start with foundation model (pre-trained), feature extraction and then fine-tuning\n"],"metadata":{"id":"x2HQwckIRd4J"}},{"cell_type":"markdown","source":["## Getting a summary of our model with `torchinfo.summary()`"],"metadata":{"id":"1b0-1fTfST5v"}},{"cell_type":"code","source":["# print a summary with torchinfo\n","from torchinfo import summary\n","\n","summary(model=model,\n","        input_size=(1, 3, 224, 224), # example of batch_size, colour_channels, height, width\n","        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n","        col_width=20,\n","        row_settings=[\"var_names\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gjssdd8MUGu8","executionInfo":{"status":"ok","timestamp":1706086710146,"user_tz":-480,"elapsed":1158,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}},"outputId":"aaa133fc-2d80-480f-a302-a2bb0f043c6e"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["============================================================================================================================================\n","Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n","============================================================================================================================================\n","EfficientNet (EfficientNet)                                  [1, 3, 224, 224]     [1, 1000]            --                   True\n","├─Sequential (features)                                      [1, 3, 224, 224]     [1, 1280, 7, 7]      --                   True\n","│    └─Conv2dNormActivation (0)                              [1, 3, 224, 224]     [1, 32, 112, 112]    --                   True\n","│    │    └─Conv2d (0)                                       [1, 3, 224, 224]     [1, 32, 112, 112]    864                  True\n","│    │    └─BatchNorm2d (1)                                  [1, 32, 112, 112]    [1, 32, 112, 112]    64                   True\n","│    │    └─SiLU (2)                                         [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n","│    └─Sequential (1)                                        [1, 32, 112, 112]    [1, 16, 112, 112]    --                   True\n","│    │    └─MBConv (0)                                       [1, 32, 112, 112]    [1, 16, 112, 112]    1,448                True\n","│    └─Sequential (2)                                        [1, 16, 112, 112]    [1, 24, 56, 56]      --                   True\n","│    │    └─MBConv (0)                                       [1, 16, 112, 112]    [1, 24, 56, 56]      6,004                True\n","│    │    └─MBConv (1)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      10,710               True\n","│    └─Sequential (3)                                        [1, 24, 56, 56]      [1, 40, 28, 28]      --                   True\n","│    │    └─MBConv (0)                                       [1, 24, 56, 56]      [1, 40, 28, 28]      15,350               True\n","│    │    └─MBConv (1)                                       [1, 40, 28, 28]      [1, 40, 28, 28]      31,290               True\n","│    └─Sequential (4)                                        [1, 40, 28, 28]      [1, 80, 14, 14]      --                   True\n","│    │    └─MBConv (0)                                       [1, 40, 28, 28]      [1, 80, 14, 14]      37,130               True\n","│    │    └─MBConv (1)                                       [1, 80, 14, 14]      [1, 80, 14, 14]      102,900              True\n","│    │    └─MBConv (2)                                       [1, 80, 14, 14]      [1, 80, 14, 14]      102,900              True\n","│    └─Sequential (5)                                        [1, 80, 14, 14]      [1, 112, 14, 14]     --                   True\n","│    │    └─MBConv (0)                                       [1, 80, 14, 14]      [1, 112, 14, 14]     126,004              True\n","│    │    └─MBConv (1)                                       [1, 112, 14, 14]     [1, 112, 14, 14]     208,572              True\n","│    │    └─MBConv (2)                                       [1, 112, 14, 14]     [1, 112, 14, 14]     208,572              True\n","│    └─Sequential (6)                                        [1, 112, 14, 14]     [1, 192, 7, 7]       --                   True\n","│    │    └─MBConv (0)                                       [1, 112, 14, 14]     [1, 192, 7, 7]       262,492              True\n","│    │    └─MBConv (1)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       587,952              True\n","│    │    └─MBConv (2)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       587,952              True\n","│    │    └─MBConv (3)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       587,952              True\n","│    └─Sequential (7)                                        [1, 192, 7, 7]       [1, 320, 7, 7]       --                   True\n","│    │    └─MBConv (0)                                       [1, 192, 7, 7]       [1, 320, 7, 7]       717,232              True\n","│    └─Conv2dNormActivation (8)                              [1, 320, 7, 7]       [1, 1280, 7, 7]      --                   True\n","│    │    └─Conv2d (0)                                       [1, 320, 7, 7]       [1, 1280, 7, 7]      409,600              True\n","│    │    └─BatchNorm2d (1)                                  [1, 1280, 7, 7]      [1, 1280, 7, 7]      2,560                True\n","│    │    └─SiLU (2)                                         [1, 1280, 7, 7]      [1, 1280, 7, 7]      --                   --\n","├─AdaptiveAvgPool2d (avgpool)                                [1, 1280, 7, 7]      [1, 1280, 1, 1]      --                   --\n","├─Sequential (classifier)                                    [1, 1280]            [1, 1000]            --                   True\n","│    └─Dropout (0)                                           [1, 1280]            [1, 1280]            --                   --\n","│    └─Linear (1)                                            [1, 1280]            [1, 1000]            1,281,000            True\n","============================================================================================================================================\n","Total params: 5,288,548\n","Trainable params: 5,288,548\n","Non-trainable params: 0\n","Total mult-adds (M): 385.87\n","============================================================================================================================================\n","Input size (MB): 0.60\n","Forward/backward pass size (MB): 107.89\n","Params size (MB): 21.15\n","Estimated Total Size (MB): 129.64\n","============================================================================================================================================"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["## Freezing the base model and changing the output layer to suit our needs\n","\n"],"metadata":{"id":"4f31gBg0Vx9s"}},{"cell_type":"code","source":["model.features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xn0oo1e9V-cF","executionInfo":{"status":"ok","timestamp":1706086710146,"user_tz":-480,"elapsed":15,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}},"outputId":"30786700-8ed4-4002-a6a0-bde578652852"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Conv2dNormActivation(\n","    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): SiLU(inplace=True)\n","  )\n","  (1): Sequential(\n","    (0): MBConv(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (1): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): SiLU(inplace=True)\n","          (scale_activation): Sigmoid()\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n","    )\n","  )\n","  (2): Sequential(\n","    (0): MBConv(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): SiLU(inplace=True)\n","          (scale_activation): Sigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n","    )\n","    (1): MBConv(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): SiLU(inplace=True)\n","          (scale_activation): Sigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n","    )\n","  )\n","  (3): Sequential(\n","    (0): MBConv(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): SiLU(inplace=True)\n","          (scale_activation): Sigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n","    )\n","    (1): MBConv(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n","          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): SiLU(inplace=True)\n","          (scale_activation): Sigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n","    )\n","  )\n","  (4): Sequential(\n","    (0): MBConv(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n","          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): SiLU(inplace=True)\n","          (scale_activation): Sigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n","    )\n","    (1): MBConv(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): SiLU(inplace=True)\n","          (scale_activation): Sigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n","    )\n","    (2): MBConv(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): SiLU(inplace=True)\n","          (scale_activation): Sigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n","    )\n","  )\n","  (5): Sequential(\n","    (0): MBConv(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n","          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): SiLU(inplace=True)\n","          (scale_activation): Sigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n","    )\n","    (1): MBConv(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): SiLU(inplace=True)\n","          (scale_activation): Sigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n","    )\n","    (2): MBConv(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): SiLU(inplace=True)\n","          (scale_activation): Sigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n","    )\n","  )\n","  (6): Sequential(\n","    (0): MBConv(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n","          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): SiLU(inplace=True)\n","          (scale_activation): Sigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n","    )\n","    (1): MBConv(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): SiLU(inplace=True)\n","          (scale_activation): Sigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n","    )\n","    (2): MBConv(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): SiLU(inplace=True)\n","          (scale_activation): Sigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n","    )\n","    (3): MBConv(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): SiLU(inplace=True)\n","          (scale_activation): Sigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n","    )\n","  )\n","  (7): Sequential(\n","    (0): MBConv(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n","          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): SiLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): SiLU(inplace=True)\n","          (scale_activation): Sigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n","    )\n","  )\n","  (8): Conv2dNormActivation(\n","    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): SiLU(inplace=True)\n","  )\n",")"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# Freeeze all the base layers in EffNetB0\n","for param in model.features.parameters():\n","  # print(param)\n","  param.requires_grad = False # Freeze all the parameters"],"metadata":{"id":"q0JuRF96V7GR","executionInfo":{"status":"ok","timestamp":1706086710146,"user_tz":-480,"elapsed":13,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Update the classifier head of the model to 3 classes\n","from torch import nn\n","torch.manual_seed(42)\n","torch.cuda.manual_seed(42)\n","\n","model.classifier = nn.Sequential(\n","    nn.Dropout(p=0.2, inplace=True), # dropout could turn off some neurons halfway through the neural network, so the rest can learn more generalisable patterns\n","    nn.Linear(in_features=1280, # 20% of these feature vectors will be dropped\n","              out_features=len(class_names), bias=True) # change the out_features\n",").to(device)"],"metadata":{"id":"TAHOg0VXW569","executionInfo":{"status":"ok","timestamp":1706086710146,"user_tz":-480,"elapsed":13,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["summary(model=model,\n","        input_size=(1, 3, 224, 224), # example of batch_size, colour_channels, height, width\n","        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n","        col_width=20,\n","        row_settings=[\"var_names\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"whmokgXWWol-","executionInfo":{"status":"ok","timestamp":1706086710147,"user_tz":-480,"elapsed":14,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}},"outputId":"1baf80f6-22d0-465c-8361-db9bca106260"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["============================================================================================================================================\n","Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n","============================================================================================================================================\n","EfficientNet (EfficientNet)                                  [1, 3, 224, 224]     [1, 3]               --                   Partial\n","├─Sequential (features)                                      [1, 3, 224, 224]     [1, 1280, 7, 7]      --                   False\n","│    └─Conv2dNormActivation (0)                              [1, 3, 224, 224]     [1, 32, 112, 112]    --                   False\n","│    │    └─Conv2d (0)                                       [1, 3, 224, 224]     [1, 32, 112, 112]    (864)                False\n","│    │    └─BatchNorm2d (1)                                  [1, 32, 112, 112]    [1, 32, 112, 112]    (64)                 False\n","│    │    └─SiLU (2)                                         [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n","│    └─Sequential (1)                                        [1, 32, 112, 112]    [1, 16, 112, 112]    --                   False\n","│    │    └─MBConv (0)                                       [1, 32, 112, 112]    [1, 16, 112, 112]    (1,448)              False\n","│    └─Sequential (2)                                        [1, 16, 112, 112]    [1, 24, 56, 56]      --                   False\n","│    │    └─MBConv (0)                                       [1, 16, 112, 112]    [1, 24, 56, 56]      (6,004)              False\n","│    │    └─MBConv (1)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      (10,710)             False\n","│    └─Sequential (3)                                        [1, 24, 56, 56]      [1, 40, 28, 28]      --                   False\n","│    │    └─MBConv (0)                                       [1, 24, 56, 56]      [1, 40, 28, 28]      (15,350)             False\n","│    │    └─MBConv (1)                                       [1, 40, 28, 28]      [1, 40, 28, 28]      (31,290)             False\n","│    └─Sequential (4)                                        [1, 40, 28, 28]      [1, 80, 14, 14]      --                   False\n","│    │    └─MBConv (0)                                       [1, 40, 28, 28]      [1, 80, 14, 14]      (37,130)             False\n","│    │    └─MBConv (1)                                       [1, 80, 14, 14]      [1, 80, 14, 14]      (102,900)            False\n","│    │    └─MBConv (2)                                       [1, 80, 14, 14]      [1, 80, 14, 14]      (102,900)            False\n","│    └─Sequential (5)                                        [1, 80, 14, 14]      [1, 112, 14, 14]     --                   False\n","│    │    └─MBConv (0)                                       [1, 80, 14, 14]      [1, 112, 14, 14]     (126,004)            False\n","│    │    └─MBConv (1)                                       [1, 112, 14, 14]     [1, 112, 14, 14]     (208,572)            False\n","│    │    └─MBConv (2)                                       [1, 112, 14, 14]     [1, 112, 14, 14]     (208,572)            False\n","│    └─Sequential (6)                                        [1, 112, 14, 14]     [1, 192, 7, 7]       --                   False\n","│    │    └─MBConv (0)                                       [1, 112, 14, 14]     [1, 192, 7, 7]       (262,492)            False\n","│    │    └─MBConv (1)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       (587,952)            False\n","│    │    └─MBConv (2)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       (587,952)            False\n","│    │    └─MBConv (3)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       (587,952)            False\n","│    └─Sequential (7)                                        [1, 192, 7, 7]       [1, 320, 7, 7]       --                   False\n","│    │    └─MBConv (0)                                       [1, 192, 7, 7]       [1, 320, 7, 7]       (717,232)            False\n","│    └─Conv2dNormActivation (8)                              [1, 320, 7, 7]       [1, 1280, 7, 7]      --                   False\n","│    │    └─Conv2d (0)                                       [1, 320, 7, 7]       [1, 1280, 7, 7]      (409,600)            False\n","│    │    └─BatchNorm2d (1)                                  [1, 1280, 7, 7]      [1, 1280, 7, 7]      (2,560)              False\n","│    │    └─SiLU (2)                                         [1, 1280, 7, 7]      [1, 1280, 7, 7]      --                   --\n","├─AdaptiveAvgPool2d (avgpool)                                [1, 1280, 7, 7]      [1, 1280, 1, 1]      --                   --\n","├─Sequential (classifier)                                    [1, 1280]            [1, 3]               --                   True\n","│    └─Dropout (0)                                           [1, 1280]            [1, 1280]            --                   --\n","│    └─Linear (1)                                            [1, 1280]            [1, 3]               3,843                True\n","============================================================================================================================================\n","Total params: 4,011,391\n","Trainable params: 3,843\n","Non-trainable params: 4,007,548\n","Total mult-adds (M): 384.59\n","============================================================================================================================================\n","Input size (MB): 0.60\n","Forward/backward pass size (MB): 107.88\n","Params size (MB): 16.05\n","Estimated Total Size (MB): 124.53\n","============================================================================================================================================"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["## Train model\n"],"metadata":{"id":"ylBVzU-LYrxx"}},{"cell_type":"code","source":["# Loss fn and optimizer\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params=model.parameters(),\n","                             lr=0.001)"],"metadata":{"id":"p7X_YRjRZKpJ","executionInfo":{"status":"ok","timestamp":1706086710147,"user_tz":-480,"elapsed":6,"user":{"displayName":"Kaushik Elangovan","userId":"00639960902829267829"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Import train function\n","from going_modular.going_modular import engine\n","\n","# Set seeds\n","torch.manual_seed(42)\n","torch.cuda.manual_seed(42)\n","\n","# Start timer\n","from timeit import default_timer as timer\n","start_time = timer()\n","\n","# Setup training and save results\n","results = engine.train(model=model,\n","                       train_dataloader=train_dataloader,\n","                       test_dataloader=test_dataloader,\n","                       optimizer=optimizer,\n","                       loss_fn=loss_fn,\n","                       epochs=5,\n","                       device=device)\n","\n","# End timer and print time\n","end_time = timer()\n","print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87,"referenced_widgets":["1b0fcc764bc54f75962eadaddd3dfc3b","f19275cf819f448da63fdc1ac1f88d50","f81278bd256d4d879c99603ad3d8a113","f9379902f80e452e802cb34060af53c7","6e061beb21cb4438b13812289de86bb8","8882758b0be84dd1b7b3f204635c6033","bdaeec842cab4cb29df985b738685d87","81125dca20e340e4b05e9e25846ce63b","9c0969ab38154245a9f5d4ec03533e00","d15585a792804f66829ce0d788d95223","70548b62ea934f239223d2c8e69f6d7c"]},"id":"0KK_0Q1HZWzK","outputId":"ca01d1ad-9f71-4c98-fc57-4cd4fcf144b0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/5 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b0fcc764bc54f75962eadaddd3dfc3b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1 | train_loss: 1.0924 | train_acc: 0.3984 | test_loss: 0.9133 | test_acc: 0.5398\n"]}]},{"cell_type":"code","source":["device # will have lower training time if cuda"],"metadata":{"id":"wv7ElDHca3tk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results"],"metadata":{"id":"-2MtHqgza5Sb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Evaluate model by plotting loss curves\n","try:\n","  from helper_functions import plot_loss_curves\n","except:\n","  print(f\"[INFO] Couldn't find helper_functions.py, downloading...\")\n","  with open(\"helper_functions.py\", \"wb\") as f:\n","    import requests\n","    request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n","    f.write(request.content)\n","    from helper_functions import plot_loss_curves\n","\n","# Plot loss curves of model\n","plot_loss_curves(results)"],"metadata":{"id":"wGBrMfxlbNHb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Make predictions on images from test set\n","\n","Ensure that the test/custom data is:\n","* Same shape - images need to be same shape as model was trained on\n","* Same datatype - custom data should be in the same datatype\n","* Same device\n","* Same transform - if transformed the custom data, ideally will transform the test data and custom data the same\n","\n","To do all this automatically, lets creata a function called `pred_and_plot_image`\n","\n","1. Take in a trained model, a list of class names, a filepath to a target image, an image size, a transform and target device\n","\n","2. Open the image with `PIL.Image.Open()`\n","\n","3. Create a transform if one doesn't exist\n","\n","4. Make sure the model is on the target device\n","\n","5. Turn model to `model.eval()` mode to get ready for inference (will turn off nn.Dropout etc)\n","\n","6. Transform the target image and make sure its dimensionality is suited for the model (unsqueeze for batch size)\n","\n","7. Make a prediction by passing image to model\n","\n","8. Convert logits to pred probs using torch.softmax\n","\n","9. Convert pred probs to pred labels using torch.argmax\n","\n","10. Plot image with `matplotlib` and set title to pred label and probability"],"metadata":{"id":"DTk2bw9QelLP"}},{"cell_type":"code","source":["from typing import List, Tuple\n","\n","from PIL import Image\n","\n","from torchvision import transforms\n","\n","import matplotlib.pyplot as plt\n","\n","# Take in a trained model\n","def pred_and_plot_image(model: torch.nn.Module,\n","                        image_path: str,\n","                        class_names: List[str],\n","                        image_size: Tuple[int, int] = (224, 224),\n","                        transform: torchvision.transforms = None,\n","                        device: torch.device=device):\n","\n","  # Open the image with PIL\n","  img = Image.open(image_path)\n","\n","  # Create transform if does not exist\n","  if transform:\n","    image_transform = transform\n","  else:\n","    image_transform = transforms.Compose([\n","        transforms.Resize((image_size)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                 std=[0.229, 0.224, 0.225])\n","    ])\n","\n","  ### Predict on image ###\n","  # Model on target device\n","  model.to(device)\n","\n","  # Inference mode and eval()\n","  model.eval()\n","  with torch.inference_mode():\n","    # Transform the image and add extra batch dimension\n","    transformed_image = image_transform(img).unsqueeze(dim=0) # [batch_size, colour_channels, height, width]\n","\n","    # Make a prediction on transformed image and ensure image on target device\n","    target_image_pred = model(transformed_image.to(device))\n","\n","    # Pred logits to pred probs\n","    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n","\n","    # Convert probs to pred labels\n","    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n","\n","    # Plot the image (pass from PIL)\n","    plt.figure()\n","    plt.imshow(img)\n","    plt.title(f\"Pred: {class_names[target_image_pred_label]} | Prob: {target_image_pred_probs.max().item():.3f}\")\n","    plt.axis(False);\n"],"metadata":{"id":"GhUkb8v7fERN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_names"],"metadata":{"id":"xqNRqAK-jxUF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get a random list of image paths from the test set\n","import random\n","num_images_to_plot = 3\n","test_image_path_list = list(Path(test_dir).glob(\"*/*.jpg\"))\n","test_image_path_sample = random.sample(population=test_image_path_list,\n","                                       k=num_images_to_plot)\n","\n","# Make predictions on and plot the images\n","for image_path in test_image_path_sample:\n","  pred_and_plot_image(model=model,\n","                      image_path=image_path,\n","                      class_names=class_names,\n","                      image_size=(224,224))"],"metadata":{"id":"FzGuabHci74M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Making predicions on a custom image"],"metadata":{"id":"oWyGXkOUkc4F"}},{"cell_type":"code","source":["# Download image\n","import requests\n","\n","# Setup custom image path\n","custom_image_path = data_path / \"04-pizza-dad.jpeg\"\n","\n","# Download image if needed\n","if not custom_image_path.is_file(): # check for file\n","  with open(custom_image_path, \"wb\") as f:\n","    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/04-pizza-dad.jpeg?raw=true\")\n","    print(f\"Download {custom_image_path}...\")\n","    f.write(request.content)\n","\n","else:\n","  print(f\"{custom_image_path} already exists, skipping download...\")"],"metadata":{"id":"XqE1ni1nkrLc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predict on custom image\n","pred_and_plot_image(model=model,\n","                    image_path=custom_image_path,\n","                    class_names=class_names)"],"metadata":{"id":"BICftQKklZF1"},"execution_count":null,"outputs":[]}]}